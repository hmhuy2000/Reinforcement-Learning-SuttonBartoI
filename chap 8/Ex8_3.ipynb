{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sns\n",
    "import random\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    height = 6\n",
    "    width = 9\n",
    "    start = [5, 3]\n",
    "    goal  = [0, 8]\n",
    "    action_Up = [-1, 0]\n",
    "    action_Down = [1, 0]\n",
    "    action_Left = [0, -1]\n",
    "    action_Right = [0, 1]\n",
    "    actions = [action_Up, action_Down, action_Left, action_Right]\n",
    "    alpha = 1.0\n",
    "    epsilon = 0.1\n",
    "    max_step = 6000\n",
    "    step_change = 3000\n",
    "    n_run = 20\n",
    "    n_plan = 5\n",
    "    garma = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "otc = [(3, 1),(3, 2),(3, 3),(3, 4),(3, 5), (3, 6),(3, 7), (3,8)]\n",
    "change_otc = [(3, 1),(3, 2),(3, 3),(3, 4),(3, 5), (3, 6),(3, 7)]\n",
    "\n",
    "def go(curX, curY, action, otc):\n",
    "    [tmpX, tmpY] = CFG.actions[action]\n",
    "    nextX = max(0, min(curX + tmpX, CFG.height - 1))\n",
    "    nextY = max(0, min(curY + tmpY, CFG.width - 1))\n",
    "    if ((nextX, nextY) in otc):\n",
    "        (nextX, nextY) = (curX, curY)\n",
    "    return (nextX, nextY)\n",
    "\n",
    "def step(curX, curY, action, otc):\n",
    "    (nextX, nextY) = go(curX, curY, action, otc)\n",
    "    if ([nextX, nextY] == CFG.goal):\n",
    "        return ([nextX, nextY], 1.0, True)\n",
    "#     if ([nextX, nextY] == [curX, curY]):\n",
    "#         return([nextX, nextY], -1, False)\n",
    "    return ([nextX, nextY], 0.0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyna_Q(n_plan, alpha = CFG.alpha, n_run = CFG.n_run, max_step = CFG.max_step):\n",
    "    res = np.zeros((max_step+1))\n",
    "    t_r = trange(n_run, desc = f'dynaQ n = {n_plan} a = {alpha}')\n",
    "    for r in t_r:\n",
    "        # Q = np.random.random((CFG.height, CFG.width, 4))\n",
    "        time = 0\n",
    "        Q = np.zeros(((CFG.height, CFG.width, 4)))\n",
    "        model = {}\n",
    "        while (time <= max_step):\n",
    "            [curX, curY] = CFG.start\n",
    "            while(True):\n",
    "                    \n",
    "                if(time>max_step):\n",
    "                    break\n",
    "                if (np.random.random()<CFG.epsilon):\n",
    "                    action = np.random.choice(np.arange(4))\n",
    "                else:\n",
    "                    set_actions = Q[curX, curY,:] == np.max(Q[curX, curY, :])\n",
    "                    actions = []\n",
    "                    for i in range(4):\n",
    "                        if (set_actions[i] == 1):\n",
    "                            actions.append(i)\n",
    "                    action = np.random.choice(actions)\n",
    "                \n",
    "                if (time >= CFG.step_change):\n",
    "                    cur_otc = change_otc\n",
    "                else:\n",
    "                    cur_otc = otc\n",
    "                (Nstate, reward, done) = step(curX, curY, action, cur_otc)\n",
    "                res[time] += reward\n",
    "                [nextX, nextY] = Nstate\n",
    "#                 print(ep, (curX, curY), action, (nextX, nextY))\n",
    "                Q[curX, curY, action] += alpha * (reward + CFG.garma * np.max(Q[nextX, nextY, :]) - Q[curX, curY, action])\n",
    "                model[((curX, curY), action)] = ((nextX, nextY), reward)\n",
    "\n",
    "                for _ in range(n_plan):\n",
    "                    idx = np.random.choice(range(len(model.keys())))\n",
    "                    ((tmpX, tmpY), tmp_action) = list(model.keys())[idx]\n",
    "                    ((tmp_NX, tmp_NY), tmp_reward) = model[((tmpX, tmpY), tmp_action)]\n",
    "                    Q[tmpX, tmpY, tmp_action] += alpha * (tmp_reward + CFG.garma * np.max(Q[tmp_NX, tmp_NY, :]) - Q[tmpX, tmpY, tmp_action])\n",
    "                time += 1\n",
    "                if (done):\n",
    "                    break\n",
    "                (curX, curY) = (nextX, nextY)\n",
    "        t_r.set_description(f'dynaQ n = {n_plan} a = {alpha} res = {np.sum(res/(r+1)):.2f}')\n",
    "            \n",
    "    return np.add.accumulate(res/n_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyna_Q_plus(n_plan, alpha = CFG.alpha, n_run = CFG.n_run, max_step = CFG.max_step):\n",
    "    res = np.zeros((max_step+1))\n",
    "    t_r = trange(n_run, desc = f'dynaQ+ n = {n_plan} a = {alpha}')\n",
    "    for r in t_r:\n",
    "        # Q = np.random.random((CFG.height, CFG.width, 4))\n",
    "        time = 0\n",
    "#         Q = np.random.random(((CFG.height, CFG.width, 4)))\n",
    "        Q = np.zeros((CFG.height, CFG.width, 4), dtype = float)\n",
    "        model = {}\n",
    "        while (time <= max_step):\n",
    "            [curX, curY] = CFG.start\n",
    "            while(True):\n",
    "#                 print((curX, curY), Q[curX, curY,:])\n",
    "                if(time>max_step):\n",
    "                    break\n",
    "                if (np.random.random()<CFG.epsilon):\n",
    "                    action = np.random.choice(np.arange(4))\n",
    "                else:\n",
    "                    set_actions = Q[curX, curY,:] == np.max(Q[curX, curY, :])\n",
    "                    actions = []\n",
    "                    for i in range(4):\n",
    "                        if (set_actions[i] == 1):\n",
    "                            actions.append(i)\n",
    "                    action = np.random.choice(actions)\n",
    "                \n",
    "                if (time >= CFG.step_change):\n",
    "                    cur_otc = change_otc\n",
    "                else:\n",
    "                    cur_otc = otc\n",
    "                (Nstate, reward, done) = step(curX, curY, action, cur_otc)\n",
    "                res[time] += reward\n",
    "                [nextX, nextY] = Nstate\n",
    "#                 print(ep, (curX, curY), action, (nextX, nextY))\n",
    "                Q[curX, curY, action] += alpha * (reward + CFG.garma * np.max(Q[nextX, nextY, :]) - Q[curX, curY, action])\n",
    "                model[deepcopy(((curX, curY), action))] = deepcopy(((nextX, nextY), reward, time))\n",
    "                for action_ in range(4):\n",
    "                    if ((deepcopy(((curX, curY), action_))) not in model.keys()):\n",
    "                        model[(deepcopy(((curX, curY), action_)))] = deepcopy(((nextX, nextY), 0, 0))\n",
    "\n",
    "                for _ in range(n_plan):\n",
    "                    idx = np.random.choice(range(len(model.keys())))\n",
    "                    ((tmpX, tmpY), tmp_action) = list(model.keys())[idx]\n",
    "                    ((tmp_NX, tmp_NY), tmp_reward, last_time) = model[((tmpX, tmpY), tmp_action)]\n",
    "                    copy_reward = deepcopy(tmp_reward)\n",
    "#                     print(f'--------{time}_{_}----------')\n",
    "                    copy_reward += 0.0001 * np.sqrt(time - last_time)\n",
    "#                     print(Q[tmpX, tmpY, tmp_action])\n",
    "#                     print((tmpX,tmpY),tmp_action,(tmp_NX, tmp_NY))\n",
    "                    Q[tmpX, tmpY, tmp_action] += alpha * (copy_reward + CFG.garma * np.max(Q[tmp_NX, tmp_NY, :]) - Q[tmpX, tmpY, tmp_action])\n",
    "#                     print(Q[tmpX, tmpY, tmp_action])\n",
    "                time += 1\n",
    "                if (done):\n",
    "                    break\n",
    "                (curX, curY) = (nextX, nextY)\n",
    "        t_r.set_description(f'dynaQ+ n = {n_plan} a = {alpha} res = {np.sum(res/(r+1)):.2f}')\n",
    "        \n",
    "            \n",
    "    return np.add.accumulate(res/n_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dynaQ n = 25 a = 0.3 res = 286.20: 100%|██████████| 20/20 [03:07<00:00,  9.36s/it]\n",
      "dynaQ n = 50 a = 0.3 res = 301.57:  35%|███▌      | 7/20 [02:20<03:52, 17.92s/it]"
     ]
    }
   ],
   "source": [
    "for alpha in [0.3,0.6,0.9,1.0]:\n",
    "    for n_plan in [25,50]:\n",
    "        plt.plot(dyna_Q(n_plan = n_plan, alpha = alpha), label = f'dyna_Q(a = {alpha} n = {n_plan})')\n",
    "#         plt.plot(dyna_Q_plus(n_plan = n_plan, alpha = alpha), label = f'dyna_Q+(a = {alpha} n = {n_plan})')\n",
    "\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('total reward')\n",
    "# plt.rcParams[\"figure.figsize\"] = (40,40)\n",
    "plt.legend()\n",
    "plt.savefig('Ex8_3/figure_Ex8_3_dynaQ.png',dpi = 1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in [0.3,0.6,0.9,1.0]:\n",
    "    for n_plan in [25,50]:\n",
    "#         plt.plot(dyna_Q(n_plan = n_plan, alpha = alpha),'--', label = f'dyna_Q(a = {alpha} n = {n_plan})')\n",
    "        plt.plot(dyna_Q_plus(n_plan = n_plan, alpha = alpha), label = f'dyna_Q+(a = {alpha} n = {n_plan})')\n",
    "\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('total reward')\n",
    "# plt.rcParams[\"figure.figsize\"] = (40,40)\n",
    "plt.legend()\n",
    "plt.savefig('Ex8_3/figure_Ex8_3_dynaQPlus.png',dpi = 1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
